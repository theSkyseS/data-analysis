{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, metrics, model_selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(f):\n",
    "    return f * (1 - f)\n",
    "\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "\n",
    "def tanh_derivative(f):\n",
    "    return 1 - np.square(f)\n",
    "\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(z, 0)\n",
    "\n",
    "\n",
    "def relu_derivative(f):\n",
    "    return int(f > 0)\n",
    "\n",
    "ACTIVATIONS = {'sigmoid': sigmoid,\n",
    "               'tanh': tanh,\n",
    "               'relu': relu}\n",
    "DERIVATIVES = {'sigmoid': sigmoid_derivative,\n",
    "               'tanh': tanh_derivative,\n",
    "               'relu': relu_derivative}\n",
    "\n",
    "def mean_squared_error(y_pred, y_true):\n",
    "    return 0.5 * (y_pred - y_true) ** 2\n",
    "\n",
    "\n",
    "def mse_derivative(y_pred, y_true):\n",
    "    return y_pred - y_true"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "class MultilayerPerceptron:\n",
    "\n",
    "    def __init__(self, layers, activation_functions, learning_rate = 0.01, min_weight_dist = 1e-8, max_iter=1e4):\n",
    "        self.layers_count = len(layers)\n",
    "        self.activation_functions = activation_functions\n",
    "        self.layers = layers\n",
    "        self.min_weight_dist = min_weight_dist\n",
    "        self.max_iter = max_iter\n",
    "        self.weights = [2 * np.random.random((x + 1, y)) - 1 for x, y in zip(layers[:-1], layers[1:])]\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        activations = [np.hstack((np.ones((x.shape[0], 1)), x))] # добавляем столбец единиц для свободного коэффициента\n",
    "        for i in range(self.layers_count - 2):\n",
    "            z = np.dot(activations[i], self.weights[i])\n",
    "            activation = ACTIVATIONS[self.activation_functions[i]](z)\n",
    "            activations.append(np.hstack((np.ones((activation.shape[0], 1)), activation))) # # добавляем столбец единиц для свободного коэффициента\n",
    "        activations.append(np.dot(activations[-1], self.weights[-1]))\n",
    "        return activations\n",
    "\n",
    "    def backpropagation(self, activations, y):\n",
    "        error = activations[-1] - y\n",
    "        weight_changes = [np.average(activations[-2][:, :, np.newaxis] * error[:, np.newaxis, :], axis=0)]\n",
    "        for i in range(2, self.layers_count):\n",
    "            error =  DERIVATIVES[self.activation_functions[-i]](activations[-i][:, 1:]) \\\n",
    "                * np.dot(error, self.weights[-i + 1].T[:, 1:])\n",
    "            delta = activations[-i - 1][:, :, np.newaxis] * error[:, np.newaxis, :]\n",
    "            weight_changes.append(np.average(delta, axis=0))\n",
    "        weight_changes.reverse()\n",
    "        return weight_changes\n",
    "\n",
    "    def update_weights(self, weight_changes):\n",
    "        for i in range(len(weight_changes) - 1):\n",
    "            self.weights[i] += - self.learning_rate * weight_changes[i]\n",
    "        self.weights[-1] += - self.learning_rate * weight_changes[-1]\n",
    "\n",
    "    def stochastic_gradient_step(self, x, y):\n",
    "        activations = self.feedforward(x)\n",
    "        weight_changes = self.backpropagation(activations, y)\n",
    "        self.update_weights(weight_changes)\n",
    "        return weight_changes\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        weight_dist = np.array((np.inf, np.inf))\n",
    "        iter_num = 0\n",
    "        batch_size = 5\n",
    "        while weight_dist.any() > self.min_weight_dist and iter_num < self.max_iter:\n",
    "            random_ind = np.random.randint(x.shape[0])\n",
    "            w_dist = self.stochastic_gradient_step(x[random_ind:random_ind+batch_size], y[random_ind:random_ind+batch_size])\n",
    "            weight_dist = []\n",
    "            for dist in w_dist:\n",
    "                weight_dist.append(np.linalg.norm(dist))\n",
    "            weight_dist = np.array(weight_dist)\n",
    "            iter_num += 1\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        activations = self.feedforward(x)\n",
    "        return activations[-1]\n",
    "\n",
    "mp = MultilayerPerceptron([3, 3, 1], ['sigmoid', 'sigmoid', 'sigmoid'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv(\"../data/titanic.csv\")\n",
    "titanic_df = titanic_df.fillna(titanic_df.mean())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerID  1313 non-null   int64  \n",
      " 1   Name         1313 non-null   object \n",
      " 2   PClass       1313 non-null   object \n",
      " 3   Age          1313 non-null   float64\n",
      " 4   Sex          1313 non-null   object \n",
      " 5   Survived     1313 non-null   int64  \n",
      " 6   SexCode      1313 non-null   int64  \n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 71.9+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "class_mapping = {'1st': 1,\n",
    "                 '2nd': 2,\n",
    "                 '3rd': 3,\n",
    "                 '*': 4 }\n",
    "\n",
    "titanic_df['PClass'] = titanic_df['PClass'].map(class_mapping)\n",
    "titanic_df['PClass'] = titanic_df['PClass'].astype('int64', copy=False)\n",
    "titanic_df = titanic_df.drop(columns='Sex')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "X = titanic_df.drop(columns=['Survived', 'Name', 'PassengerID'])\n",
    "y = titanic_df['Survived']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y).reshape(y.shape[0], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.75)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "titanic_mp = MultilayerPerceptron([3, 5, 3, 1], ['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid'], 0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "titanic_mp.fit(X_train, y_train)\n",
    "k = titanic_mp.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "classes = []\n",
    "for pred in k:\n",
    "    if pred >= 0.5:\n",
    "        classes.append(1)\n",
    "    else:\n",
    "        classes.append(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[211   4]\n",
      " [ 71  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85       215\n",
      "           1       0.91      0.38      0.53       114\n",
      "\n",
      "    accuracy                           0.77       329\n",
      "   macro avg       0.83      0.68      0.69       329\n",
      "weighted avg       0.81      0.77      0.74       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, classes))\n",
    "print(metrics.classification_report(y_test, classes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "y_iris = y_iris.reshape(y_iris.shape[0], 1)\n",
    "\n",
    "\n",
    "X_iris_train, X_iris_test, y_iris_train, y_iris_test = model_selection.train_test_split(X_iris, y_iris, train_size=0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "iris_mp = MultilayerPerceptron([4, 10, 10, 1], ['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid'], 0.1)\n",
    "iris_mp.fit(X_iris_train, y_iris_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "iris_pred = iris_mp.predict(X_iris_test)\n",
    "iris_classes = []\n",
    "for pred in iris_pred:\n",
    "    if pred < 0.5:\n",
    "        iris_classes.append(0)\n",
    "    elif pred <= 1.5:\n",
    "        iris_classes.append(1)\n",
    "    elif pred <= 2.5:\n",
    "        iris_classes.append(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  0  0]\n",
      " [ 0  7  3]\n",
      " [ 0  0 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      0.70      0.82        10\n",
      "           2       0.81      1.00      0.90        13\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.94      0.90      0.91        30\n",
      "weighted avg       0.92      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_iris_test, iris_classes))\n",
    "print(metrics.classification_report(y_iris_test, iris_classes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}