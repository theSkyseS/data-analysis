{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, metrics, model_selection, linear_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Многослойный перцептрон"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Функции активации и функция ошибки"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Логистическая функция активации\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z: array_like, float\n",
    "            аргумент функции\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        f :\n",
    "            Результат вычисления функции, принимает значения в промежутке [0, 1]\n",
    "        \"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(f):\n",
    "    \"\"\"Производная логистической функции активации\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        f : array_like, float\n",
    "            Результат вычисления функции активации\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        f' :\n",
    "            Результат вычисления производной\n",
    "        \"\"\"\n",
    "    return f * (1 - f)\n",
    "\n",
    "\n",
    "def tanh(z):\n",
    "    \"\"\"Функция активации - гиперболический тангенс\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z: array_like, float\n",
    "            аргумент функции\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        f :\n",
    "            Результат вычисления функции, принимает значения в промежутке [-1, 1]\n",
    "        \"\"\"\n",
    "    return np.tanh(z)\n",
    "\n",
    "\n",
    "def tanh_derivative(f):\n",
    "    \"\"\"Производная гиперболического тангенса\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        f : array_like, float\n",
    "            Результат вычисления функции активации\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df : array_like, float\n",
    "            Результат вычисления производной\n",
    "        \"\"\"\n",
    "    return 1 - np.square(f)\n",
    "\n",
    "\n",
    "def relu(z):\n",
    "    \"\"\"Функция активации - линейный выпрямитель\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z: array_like, float\n",
    "            аргумент функции\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        f :\n",
    "            Результат вычисления функции, принимает значения в промежутке [0, +inf)\n",
    "        \"\"\"\n",
    "    return np.maximum(z, 0)\n",
    "\n",
    "\n",
    "def relu_derivative(f):\n",
    "    \"\"\"Производная линейного выпрямителя\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        f : array_like, float\n",
    "            Результат вычисления функции активации\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df : array_like, float\n",
    "            Результат вычисления производной\n",
    "        \"\"\"\n",
    "    der = np.where(f < 0, 0, 1)\n",
    "    return der\n",
    "\n",
    "\n",
    "\n",
    "ACTIVATIONS = {'sigmoid': sigmoid,\n",
    "               'tanh': tanh,\n",
    "               'relu': relu}\n",
    "DERIVATIVES = {'sigmoid': sigmoid_derivative,\n",
    "               'tanh': tanh_derivative,\n",
    "               'relu': relu_derivative}\n",
    "\n",
    "def mean_squared_error(y_pred, y_true):\n",
    "    \"\"\"Средняя квадратичная ошибка\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : array_like\n",
    "            Предсказанные значения ключевого атрибута\n",
    "        y_true : array_like\n",
    "            Истинные значения ключевого атрибута\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mse : float\n",
    "            Средняя квадратичная ошибка\n",
    "        \"\"\"\n",
    "    return 0.5 * (y_pred - y_true) ** 2\n",
    "\n",
    "\n",
    "def mse_derivative(y_pred, y_true):\n",
    "    \"\"\"Производная средней квадратичной ошибки\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : array_like\n",
    "            Предсказанные значения ключевого атрибута\n",
    "        y_true : array_like\n",
    "            Истинные значения ключевого атрибута\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        d mse : float\n",
    "            Производная средней квадратичной ошибки\n",
    "        \"\"\"\n",
    "    return y_pred - y_true"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Реализация многослойного перцептрона"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class MultilayerPerceptron:\n",
    "    \"\"\"Многослойный перцептрон\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        layers : array_like\n",
    "            Список размеров слоёв, где каждый элемент - размер соответствующего слоя.\n",
    "            Первый слой должен иметь размер, равный количеству атрибутов объектов выборки.\n",
    "        activation_functions : array_like\n",
    "            Список функций активации для каждого слоя.\n",
    "        learning_rate : float\n",
    "            Скорость обучения, коэффициент, на который на каждом шаге умножается значение градиента.\n",
    "        \"\"\"\n",
    "    def __init__(self, layers, activation_functions, learning_rate = 0.01):\n",
    "        self.layers_count = len(layers)\n",
    "        self.activation_functions = activation_functions\n",
    "        self.layers = layers\n",
    "        self.weights = [2 * np.random.random((x + 1, y)) - 1 for x, y in zip(layers[:-1], layers[1:])]\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        \"\"\"Прямое распространение ошибки\\n\n",
    "        Для каждого слоя подсчитывается значение функции активации от взвешенных значений предыдущего слоя.\\n\n",
    "        sigma(z), где z = w*x так как для каждого слоя добавляется столбец единиц.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array_like\n",
    "            Объекты обучающей выборки.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        activations : array_like\n",
    "            Значения функции активации для каждого слоя.\n",
    "        \"\"\"\n",
    "        activations = [np.hstack((np.ones((x.shape[0], 1)), x))] # добавляем столбец единиц для свободного коэффициента\n",
    "        for i in range(self.layers_count - 2):\n",
    "            z = np.dot(activations[i], self.weights[i])\n",
    "            activation = ACTIVATIONS[self.activation_functions[i]](z)\n",
    "            activations.append(np.hstack((np.ones((activation.shape[0], 1)), activation)))  # добавляем столбец единиц для свободного коэффициента\n",
    "        activations.append(np.dot(activations[-1], self.weights[-1]))\n",
    "        return activations\n",
    "\n",
    "    def backpropagation(self, activations, y):\n",
    "        \"\"\"Обратное распространение ошибки\\n\n",
    "        Для изменения весов нейронов внешнего слоя используется значение производной от средней квадратичной ошибки.\\n\n",
    "        Для изменения весов каждого скрытого слоя используются значения ошибки подсчитанные для предыдущего слоя.\\n\n",
    "        Ошибка скрытого слоя равна произведению производной от функции активации на ошибки предыдущего слоя умноженные на веса данного слоя.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        activations : array_like\n",
    "            Изменения весов.\n",
    "        y : array_like\n",
    "            Истинные значения ключевого атрибута.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        weight_changes : array_like\n",
    "            Изменения весов для каждого слоя.\n",
    "        \"\"\"\n",
    "        error = mse_derivative(activations[-1], y)\n",
    "        weight_changes = [np.average(activations[-2][:, :, np.newaxis] * error[:, np.newaxis, :], axis=0)]\n",
    "        for i in range(2, self.layers_count):\n",
    "            error =  DERIVATIVES[self.activation_functions[-i]](activations[-i][:, 1:]) \\\n",
    "                * np.dot(error, self.weights[-i + 1].T[:, 1:])\n",
    "            delta = activations[-i - 1][:, :, np.newaxis] * error[:, np.newaxis, :]\n",
    "            weight_changes.append(np.average(delta, axis=0))\n",
    "        weight_changes.reverse()\n",
    "        return weight_changes\n",
    "\n",
    "    def update_weights(self, weight_changes):\n",
    "        \"\"\"Обновляет веса в соответствии со значениями градиента\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        weight_changes : array_like\n",
    "            Изменения весов.\n",
    "        \"\"\"\n",
    "        for i in range(len(weight_changes) - 1):\n",
    "            self.weights[i] += - self.learning_rate * weight_changes[i]\n",
    "        self.weights[-1] += - self.learning_rate * weight_changes[-1]\n",
    "\n",
    "    def stochastic_gradient_step(self, x, y):\n",
    "        \"\"\"Шаг градиентного спуска\\n\n",
    "        На каждом шаге выполняются три действия:\n",
    "            1) прямое распространение ошибки;\n",
    "            2) обратное распространение ошибки;\n",
    "            3) изменения весов.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array_like\n",
    "            Объекты обучающей выборки.\n",
    "        y : array_like\n",
    "            Истинные значения ключевого атрибута.\n",
    "        \"\"\"\n",
    "        activations = self.feedforward(x)\n",
    "        weight_changes = self.backpropagation(activations, y)\n",
    "        self.update_weights(weight_changes)\n",
    "        return weight_changes\n",
    "\n",
    "    def fit(self, x, y, min_weight_dist = 1e-8, max_iter=1e4, batch_size = 5):\n",
    "        \"\"\"Запускает процесс обучения сети с помощью алгоритмов\n",
    "        стохастического градиента спуска и обратного распространения ошибки.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array_like\n",
    "            Объекты обучающей выборки.\n",
    "        y : array_like\n",
    "            Истинные значения ключевого атрибута.\n",
    "        min_weight_dist : float\n",
    "            Минимальное изменение весов.\n",
    "        max_iter : float\n",
    "            Максимальное число итераций градиентного спуска.\n",
    "        batch_size: int\n",
    "            Количество объектов в подвыборке\n",
    "        \"\"\"\n",
    "        weight_dist = np.array((np.inf, np.inf))\n",
    "        iter_num = 0\n",
    "        while weight_dist.any() > min_weight_dist and iter_num < max_iter:\n",
    "            random_ind = np.random.randint(x.shape[0])\n",
    "            w_dist = self.stochastic_gradient_step(x[random_ind:random_ind+batch_size], y[random_ind:random_ind+batch_size])\n",
    "            weight_dist = []\n",
    "            for dist in w_dist:\n",
    "                weight_dist.append(np.linalg.norm(dist))\n",
    "            weight_dist = np.array(weight_dist)\n",
    "            iter_num += 1\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Предсказывает значения ключевого атрибута на объектах выборки.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array_like\n",
    "            Объекты выборки.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array_like\n",
    "            Предсказанные значения ключевого атрибута.\n",
    "        \"\"\"\n",
    "        activations = self.feedforward(x)\n",
    "        return activations[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Проверка работы реализации многослойного перцептрона на наборе данных \"Titanic\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerID  1313 non-null   int64  \n",
      " 1   Name         1313 non-null   object \n",
      " 2   PClass       1313 non-null   object \n",
      " 3   Age          756 non-null    float64\n",
      " 4   Sex          1313 non-null   object \n",
      " 5   Survived     1313 non-null   int64  \n",
      " 6   SexCode      1313 non-null   int64  \n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 71.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Импортируем датасет\n",
    "titanic_df = pd.read_csv(\"../data/titanic.csv\")\n",
    "titanic_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Проводим предобработку данных\n",
    "# Заполняем пропуски средними значениями\n",
    "titanic_df = titanic_df.fillna(titanic_df.mean())\n",
    "\n",
    "# Перекодируем категориальный атрибут\n",
    "class_mapping = {'1st': 1,\n",
    "                 '2nd': 2,\n",
    "                 '3rd': 3,\n",
    "                 '*': 4 }\n",
    "\n",
    "titanic_df['PClass'] = titanic_df['PClass'].map(class_mapping)\n",
    "titanic_df['PClass'] = titanic_df['PClass'].astype('int64', copy=False)\n",
    "\n",
    "# Отбрасываем ненужный признак, так как у нас есть признак \"SexCode\"\n",
    "titanic_df = titanic_df.drop(columns='Sex')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Разделяем выборку, а также отбрасываем бесполезные атрибуты 'Name' и 'PassengerID'\n",
    "X_titanic = titanic_df.drop(columns=['Survived', 'Name', 'PassengerID'])\n",
    "y_titanic = titanic_df['Survived']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Разделяем выборку на обучающую и тестирующую\n",
    "X_titanic = np.array(X_titanic)\n",
    "y_titanic = np.array(y_titanic).reshape(y_titanic.shape[0], 1)\n",
    "\n",
    "X_titanic_train, X_titanic_test, y_titanic_train, y_titanic_test = model_selection.train_test_split(X_titanic, y_titanic, train_size=0.75)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# Инициализируем многослойный перцептрон и логистическую регрессию\n",
    "titanic_lc = linear_model.LogisticRegression()\n",
    "titanic_mp = MultilayerPerceptron([3, 5, 4, 3, 1], ['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid'], 0.05)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Обучаем модели и получаем результаты\n",
    "titanic_mp.fit(X_titanic_train, y_titanic_train)\n",
    "titanic_mp_pred = titanic_mp.predict(X_titanic_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "titanic_lc_train = y_titanic_train.ravel()\n",
    "titanic_lc.fit(X_titanic_train, titanic_lc_train)\n",
    "titanic_lc_pred = titanic_lc.predict(X_titanic_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# Переводим предсказания вероятностей в предсказания классов\n",
    "titanic_classes = []\n",
    "for pred in titanic_mp_pred:\n",
    "    if pred >= 0.5:\n",
    "        titanic_classes.append(1)\n",
    "    else:\n",
    "        titanic_classes.append(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron:\n",
      "[[204  17]\n",
      " [ 56  52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.85       221\n",
      "           1       0.75      0.48      0.59       108\n",
      "\n",
      "    accuracy                           0.78       329\n",
      "   macro avg       0.77      0.70      0.72       329\n",
      "weighted avg       0.77      0.78      0.76       329\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "[[207  14]\n",
      " [ 44  64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       221\n",
      "           1       0.82      0.59      0.69       108\n",
      "\n",
      "    accuracy                           0.82       329\n",
      "   macro avg       0.82      0.76      0.78       329\n",
      "weighted avg       0.82      0.82      0.82       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Выводим результаты работы моделей\n",
    "print(\"Multilayer Perceptron:\")\n",
    "print(metrics.confusion_matrix(y_titanic_test, titanic_classes))\n",
    "print(metrics.classification_report(y_titanic_test, titanic_classes))\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(metrics.confusion_matrix(y_titanic_test, titanic_lc_pred))\n",
    "print(metrics.classification_report(y_titanic_test, titanic_lc_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что сеть с двумя скрытыми слоями отработала чуть хуже линейной без подбора параметров"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Проверка работы реализации многослойного перцептрона на наборе данных \"Iris\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Загружаем данные и разделяем их на обучающую и тестовую выборки\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "y_iris = y_iris.reshape(y_iris.shape[0], 1)\n",
    "\n",
    "X_iris_train, X_iris_test, y_iris_train, y_iris_test = model_selection.train_test_split(X_iris, y_iris, train_size=0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Инициализируем модели\n",
    "\n",
    "iris_lr = linear_model.LogisticRegression()\n",
    "iris_mp = MultilayerPerceptron([4, 10, 10, 1], ['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid'], 0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Обучаем модели\n",
    "iris_mp.fit(X_iris_train, y_iris_train)\n",
    "iris_mp_pred = iris_mp.predict(X_iris_test)\n",
    "iris_classes = []\n",
    "for pred in iris_mp_pred:\n",
    "    if pred < 0.5:\n",
    "        iris_classes.append(0)\n",
    "    elif pred <= 1.5:\n",
    "        iris_classes.append(1)\n",
    "    elif pred <= 2.5:\n",
    "        iris_classes.append(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "y_iris_lr = y_iris_train.ravel()\n",
    "iris_lr.fit(X_iris_train, y_iris_lr)\n",
    "iris_lr_pred = iris_lr.predict(X_iris_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron:\n",
      "[[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "Linear Regression:\n",
      "[[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  1 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.89      0.89      0.89         9\n",
      "           2       0.91      0.91      0.91        11\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Выводим результаты работы моделей\n",
    "print(\"Multilayer Perceptron:\")\n",
    "print(metrics.confusion_matrix(y_iris_test, iris_classes))\n",
    "print(metrics.classification_report(y_iris_test, iris_classes))\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(metrics.confusion_matrix(y_iris_test, iris_lr_pred))\n",
    "print(metrics.classification_report(y_iris_test, iris_lr_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что на данном наборе данных четырёхслойная сеть отработала на уровне с линейной"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Проверка работы реализации многослойного перцептрона на наборе данных \"Auto mpg\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# Импортируем набор данных, разделяем на обучающую и тестирующую выборки\n",
    "mpg_df = pd.read_csv(\"../data/auto_mpg_preprocessed.csv\")\n",
    "mpg_df = mpg_df.drop(columns=[\"Unnamed: 0\", 'car name'])\n",
    "\n",
    "X_mpg = mpg_df.drop(columns='mpg')\n",
    "y_mpg = mpg_df['mpg']\n",
    "\n",
    "y_mpg = np.array(y_mpg)\n",
    "y_mpg = y_mpg.reshape(y_mpg.shape[0], 1)\n",
    "\n",
    "X_mpg_train, X_mpg_test, y_mpg_train, y_mpg_test = model_selection.train_test_split(X_mpg, y_mpg, train_size=0.75)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Обучаем модели на масштабированных данных\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_mpg_train = scaler.fit_transform(X_mpg_train, y_mpg_train)\n",
    "X_mpg_test = scaler.transform(X_mpg_test)\n",
    "\n",
    "mpg_mp = MultilayerPerceptron([7, 15, 15, 1], ['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid'])\n",
    "mpg_mp.fit(X_mpg_train, y_mpg_train)\n",
    "mpg_mp_predict = mpg_mp.predict(X_mpg_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "mpg_lr = linear_model.LinearRegression()\n",
    "mpg_lr.fit(X_mpg_train, y_mpg_train.ravel())\n",
    "mpg_lr_predict = mpg_lr.predict(X_mpg_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron:\n",
      "MSE:  4.8514021593132055\n",
      "MAE:  1.6903907213857643\n",
      "R2:  0.9008892713715522\n",
      "\n",
      "Linear Regression:\n",
      "MSE:  8.252112074971302\n",
      "MAE:  2.3470766201678424\n",
      "R2:  0.8314151633659244\n"
     ]
    }
   ],
   "source": [
    "# Выводим результаты\n",
    "\n",
    "print(\"Multilayer Perceptron:\")\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_mpg_test, mpg_mp_predict))\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_mpg_test, mpg_mp_predict))\n",
    "print(\"R2: \", metrics.r2_score(y_mpg_test, mpg_mp_predict))\n",
    "\n",
    "print(\"\\nLinear Regression:\")\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_mpg_test, mpg_lr_predict))\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_mpg_test, mpg_lr_predict))\n",
    "print(\"R2: \", metrics.r2_score(y_mpg_test, mpg_lr_predict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что на данном наборе данных сеть отработала лучше линейной регрессии"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Проверка работы реализации многослойного перцептрона на наборе данных \"Wine\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# Импортируем набор данных, разделяем на обучающую и тестирующую выборки\n",
    "wine_df = pd.read_csv(\"../data/wine_preprocessed.csv\")\n",
    "wine_df = wine_df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "X_wine = wine_df.drop(columns='Cultivar')\n",
    "y_wine = wine_df['Cultivar']\n",
    "\n",
    "y_wine = np.array(y_wine)\n",
    "y_wine = y_wine.reshape(y_wine.shape[0], 1)\n",
    "\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = model_selection.train_test_split(X_wine, y_wine, train_size=0.75)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Обучаем модели на масштабированных данных\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_wine_train = scaler.fit_transform(X_wine_train, y_wine_train)\n",
    "X_wine_test = scaler.transform(X_wine_test)\n",
    "\n",
    "wine_mp = MultilayerPerceptron([13, 15, 15, 1], ['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid'])\n",
    "wine_mp.fit(X_wine_train, y_wine_train)\n",
    "wine_mp_predict = wine_mp.predict(X_wine_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "wine_classes = []\n",
    "for pred in wine_mp_predict:\n",
    "    if pred < 0.5:\n",
    "        wine_classes.append(0)\n",
    "    elif pred <= 1.5:\n",
    "        wine_classes.append(1)\n",
    "    elif pred <= 2.5:\n",
    "        wine_classes.append(2)\n",
    "    else:\n",
    "        wine_classes.append(3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "wine_lc = linear_model.LogisticRegression()\n",
    "wine_lc.fit(X_wine_train, y_wine_train.ravel())\n",
    "wine_lc_predict = wine_lc.predict(X_wine_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron:\n",
      "[[16  0  0]\n",
      " [ 1 15  1]\n",
      " [ 0  0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      1.00      0.97        16\n",
      "           2       1.00      0.88      0.94        17\n",
      "           3       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.95        45\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "[[16  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00        17\n",
      "           3       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Выводим результаты\n",
    "print(\"Multilayer Perceptron:\")\n",
    "print(metrics.confusion_matrix(y_wine_test, wine_classes))\n",
    "print(metrics.classification_report(y_wine_test, wine_classes))\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(metrics.confusion_matrix(y_wine_test, wine_lc_predict))\n",
    "print(metrics.classification_report(y_wine_test, wine_lc_predict))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что на данном наборе данных сеть отработала примерно на одном уровне с логистической регрессией"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}