{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree, ensemble, metrics, preprocessing, model_selection, linear_model, svm\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def print_classification_metrics(estimator, X_test, y_pred, y_test):\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(estimator.score(X_test, y_test))\n",
    "\n",
    "\n",
    "def print_regression_metrics(estimator, y_pred, y_test):\n",
    "    print('MSE:', metrics.mean_squared_error(y_test, y_pred, squared=True))\n",
    "    print('RMSE:', metrics.mean_squared_error(y_test, y_pred, squared=False))\n",
    "    print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('R2 Score:', metrics.r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "def grid_search_result(estimator, param_grid, X_train, y_train, X_test, y_test, regression=False):\n",
    "    grid_search = model_selection.GridSearchCV(estimator, param_grid, cv=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    print('Best params: ', grid_search.best_params_)\n",
    "    if regression:\n",
    "        print_regression_metrics(estimator, y_pred, y_test)\n",
    "    else:\n",
    "        print_classification_metrics(grid_search, X_test, y_pred, y_test)\n",
    "    return grid_search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Композиции алгоритмов\n",
    "\n",
    "В данной работе рассмотрены такие композиции алгоритмов как бэггинг, бустинг и стекинг."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Классификация\n",
    "\n",
    "Для классификации в качестве базового алгоритма был выбран DecisionTreeClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Подготовка данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv(\"../data/wine_preprocessed.csv\")\n",
    "wine_df = wine_df.drop(columns='Unnamed: 0')\n",
    "\n",
    "X_wine = wine_df.drop(columns='Cultivar')\n",
    "y_wine = wine_df['Cultivar'].ravel()\n",
    "\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = model_selection.train_test_split(X_wine, y_wine, test_size=0.2, stratify=y_wine)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_wine_train = scaler.fit_transform(X_wine_train, y_wine_train)\n",
    "X_wine_test = scaler.transform(X_wine_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Базовый алгоритм"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'max_depth': 5, 'min_samples_leaf': 1}\n",
      "[[10  1  1]\n",
      " [ 0 13  1]\n",
      " [ 0  0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.83      0.91        12\n",
      "           2       0.93      0.93      0.93        14\n",
      "           3       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.92      0.92      0.92        36\n",
      "weighted avg       0.93      0.92      0.92        36\n",
      "\n",
      "0.9166666666666666\n",
      "Wall time: 676 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tree_classifier = tree.DecisionTreeClassifier()\n",
    "tree_classifier_param_grid = dict(max_depth=[2, 3, 5, 7, 9, 10, 12, 15, 17, 20, 25, None], min_samples_leaf=np.arange(1, 15, 1))\n",
    "\n",
    "best_tree = grid_search_result(tree_classifier, tree_classifier_param_grid, X_wine_train, y_wine_train, X_wine_test, y_wine_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Бэггинг"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'bootstrap_features': True, 'max_features': 3, 'n_estimators': 21}\n",
      "[[12  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  1  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       0.93      1.00      0.97        14\n",
      "           3       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "0.9722222222222222\n",
      "Wall time: 9.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bagging_classifier = ensemble.BaggingClassifier(best_tree)\n",
    "bagging_classifier_param_grid = dict(n_estimators= np.arange(1, 102, 20),\n",
    "                                     max_features= np.arange(3, 14, 2),\n",
    "                                    bootstrap_features= [True])\n",
    "\n",
    "best_bagging = grid_search_result(bagging_classifier, bagging_classifier_param_grid, X_wine_train, y_wine_train, X_wine_test, y_wine_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Градиентный бустинг"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'max_features': 5, 'n_estimators': 11}\n",
      "[[12  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "1.0\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "boosting_classifier = ensemble.GradientBoostingClassifier(max_depth=best_tree.max_depth, min_samples_leaf=best_tree.min_samples_leaf)\n",
    "boosting_classifier_param_grid = dict(n_estimators= np.arange(1, 102, 10),\n",
    "                                      max_features= np.arange(3, 14, 2))\n",
    "\n",
    "best_boosting = grid_search_result(boosting_classifier, boosting_classifier_param_grid, X_wine_train, y_wine_train, X_wine_test, y_wine_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Стекинг"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "1.0\n",
      "Wall time: 551 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacking_classifier = ensemble.StackingClassifier(estimators=[('bagging', best_bagging), ('boosting', best_boosting), ('SVM', svm.SVC()), ('LR', linear_model.LogisticRegression())])\n",
    "stacking_classifier.fit(X_wine_train, y_wine_train)\n",
    "stacking_classifier_pred = stacking_classifier.predict(X_wine_test)\n",
    "print_classification_metrics(stacking_classifier, X_wine_test, stacking_classifier_pred, y_wine_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### CatBoostClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "1.0\n",
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "catboost_classifier = CatBoostClassifier(verbose=False)\n",
    "catboost_classifier.fit(X_wine_train, y_wine_train)\n",
    "catboost_classifier_pred = catboost_classifier.predict(X_wine_test)\n",
    "print_classification_metrics(catboost_classifier, X_wine_test,catboost_classifier_pred, y_wine_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Вывод\n",
    "\n",
    "Наиболее точную оценку выдали бустинг и стекинг, однако, время обучения бустинга намного больше, чем время обучения беггинга и catboost.\n",
    "Быстрее всего обучаются CatBoost из-за отсутствия необходимости подбора гиперпараметров на данном наборе данных."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Регрессия\n",
    "\n",
    "В качестве базового алгоритма для регрессии выбран DecisionTreeRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Подготовка данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "mpg_df = pd.read_csv(\"../data/auto_mpg_preprocessed.csv\")\n",
    "mpg_df = mpg_df.drop(columns=['Unnamed: 0', 'car name'])\n",
    "\n",
    "X_mpg = mpg_df.drop(columns='mpg')\n",
    "y_mpg = mpg_df['mpg'].ravel()\n",
    "\n",
    "X_mpg_train, X_mpg_test, y_mpg_train, y_mpg_test = model_selection.train_test_split(X_mpg, y_mpg, test_size=0.2)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_mpg_train = scaler.fit_transform(X_mpg_train, y_mpg_train)\n",
    "X_mpg_test = scaler.transform(X_mpg_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Базовый алгоритм"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'max_depth': 20, 'min_samples_leaf': 6}\n",
      "MSE: 6.325772412627799\n",
      "RMSE: 2.515108827193726\n",
      "MAE: 1.92393272690741\n",
      "R2 Score: 0.8901397708724341\n",
      "Wall time: 634 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tree_regressor = tree.DecisionTreeRegressor() # linear_model.ElasticNet()\n",
    "tree_regressor_param_grid = tree_classifier_param_grid # dict(alpha=np.arange(0.05, 1, 0.05), l1_ratio=np.arange(0.1, 1, 0.05))\n",
    "best_tree_regressor = grid_search_result(tree_regressor, tree_regressor_param_grid, X_mpg_train, y_mpg_train, X_mpg_test, y_mpg_test, regression=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Бэггинг"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'bootstrap_features': True, 'max_features': 7, 'n_estimators': 61}\n",
      "MSE: 6.018668007977554\n",
      "RMSE: 2.45329737455074\n",
      "MAE: 1.9417190474716488\n",
      "R2 Score: 0.895473279266383\n",
      "Wall time: 8.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bagging_regressor = ensemble.BaggingRegressor(best_tree_regressor)\n",
    "bagging_regressor_param_grid = dict(n_estimators= np.arange(1, 102, 20),\n",
    "                                     max_features= np.arange(2, 8, 1),\n",
    "                                    bootstrap_features= [True])\n",
    "\n",
    "best_bagging_regressor = grid_search_result(bagging_regressor, bagging_regressor_param_grid, X_mpg_train, y_mpg_train, X_mpg_test, y_mpg_test, regression=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Градиентный бустинг"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'max_features': 2, 'n_estimators': 41}\n",
      "MSE: 5.054755685940222\n",
      "RMSE: 2.24827838266088\n",
      "MAE: 1.8013051326427074\n",
      "R2 Score: 0.9122136267924039\n",
      "Wall time: 4.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "boosting_regressor = ensemble.GradientBoostingRegressor(max_depth=best_tree_regressor.max_depth, min_samples_leaf=best_tree_regressor.min_samples_leaf)\n",
    "boosting_regressor_param_grid = dict(n_estimators= np.arange(1, 102, 10),\n",
    "                                     max_features= np.arange(2, 8, 1))\n",
    "\n",
    "best_boosting_regressor = grid_search_result(boosting_regressor, boosting_regressor_param_grid, X_mpg_train, y_mpg_train, X_mpg_test, y_mpg_test, regression=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Стекинг"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4.9988609471827905\n",
      "RMSE: 2.235813263039378\n",
      "MAE: 1.7673711447931777\n",
      "R2 Score: 0.9131843554886591\n",
      "Wall time: 715 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacking_regressor = ensemble.StackingRegressor(estimators=[('bagging', best_bagging_regressor), ('boosting',best_boosting_regressor)])\n",
    "stacking_regressor.fit(X_mpg_train, y_mpg_train)\n",
    "stacking_regressor_pred = stacking_regressor.predict(X_mpg_test)\n",
    "print_regression_metrics(stacking_regressor, stacking_regressor_pred, y_mpg_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### CatBoostRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4.553437743800773\n",
      "RMSE: 2.1338785681947257\n",
      "MAE: 1.6982451893331165\n",
      "R2 Score: 0.9209200582598491\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "catboost_regressor = CatBoostRegressor(verbose=False)\n",
    "catboost_regressor.fit(X_mpg_train, y_mpg_train)\n",
    "catboost_regressor_pred = catboost_regressor.predict(X_mpg_test)\n",
    "print_regression_metrics(catboost_regressor , catboost_regressor_pred, y_mpg_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Вывод\n",
    "\n",
    "На данном наборе данных лучшей композицией оказался CatBoost, который без подбора параметров на данном наборе данных выдал наименьшую ошибку, за малое время обучения.\n",
    "Стоит заметить, что использование композиций позволило сократить среднюю абсолютную ошибку с 1.9 до 1.7, что является достаточно малой величиной по сравнению со значениями ключевого атрибута, которые принимают значения от 9 до 50."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}